# AI Provider Configuration
# Priority: AI_PROVIDER env var > Claude > OpenAI > Ollama (fallback)

# Force a specific provider (optional)
# Options: claude, openai, ollama
# AI_PROVIDER=ollama

# ===========================================
# OPTION 1: Ollama (FREE - Local AI)
# ===========================================
# Install Ollama: https://ollama.com/download
# Then run: ollama pull llama3.2
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ===========================================
# OPTION 2: Anthropic Claude API
# ===========================================
# Get yours at: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-your-api-key-here

# ===========================================
# OPTION 3: OpenAI API
# ===========================================
# Get yours at: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-openai-api-key-here

# ===========================================
# Database (required)
# ===========================================
DATABASE_URL=file:./dev.db

# To use this file:
# 1. Copy this file to .env.local
# 2. Configure your preferred AI provider above
# 3. Restart the development server
